{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00beda90-5218-47db-a971-fe824c0b92cc",
   "metadata": {},
   "source": [
    "# GRU model\n",
    "\n",
    "We start by importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b125c3-7f05-45ba-8815-cd3ef899ecfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from core.util.plot_predictions import plot_predictions\n",
    "from core.util.get_datasets import get_test_set\n",
    "from core.util.trefor_dataset import TreforData\n",
    "from core.models import GRU\n",
    "from core.models.model_training import blocked_training, test_model\n",
    "from core.util.hyperparameter_configuration import get_hyperparameter_configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0385b66-308f-41e6-b9b8-597225348dee",
   "metadata": {},
   "source": [
    "## Setup\n",
    "This section contains the setup for converting our data to something PyTorch can understand.\n",
    "### Set hyperparameters for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4685e80-cc1d-4e8d-b82d-c8c1454c83ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be modified depending on gridsearch result\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "num_layers = 1\n",
    "lookback = 36\n",
    "\n",
    "# Extract hyperparameters configuration that will not be tuned upon\n",
    "(\n",
    "    hidden_size,\n",
    "    EPOCHS,\n",
    "    horizon,\n",
    "    loss_function,\n",
    "    dropout_rate,\n",
    "    folds,\n",
    "    early_stopper,\n",
    ") = get_hyperparameter_configuration()\n",
    "\n",
    "model_input_size = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67712300-9f7e-4716-a493-654b4e805f7f",
   "metadata": {},
   "source": [
    "### If the host has CUDA, it will use the GPU for computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffa0eff-01ad-4f3a-a126-2e2922e2c037",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549ff68c-2cb3-4c5d-8cd0-adf75327c008",
   "metadata": {},
   "source": [
    "### Creation of our simple GRU model\n",
    "The implementation consist of three layers, defined in the `forward` method.\n",
    "1. GRU\n",
    "2. LeakyReLU\n",
    "3. Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0f4b1c-fe92-42a4-9eb6-e5e450e9555f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model() -> nn.Module:\n",
    "    \"\"\"Get the model for training folds.\"\"\"\n",
    "    model = GRU(\n",
    "        input_size=model_input_size,\n",
    "        hidden_size=hidden_size,\n",
    "        num_layers=num_layers,\n",
    "        dropout_rate=dropout_rate,\n",
    "        horizon=horizon,\n",
    "        lookback=lookback,\n",
    "    )\n",
    "    model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0617c025-6834-466c-aa64-f07bf95692ea",
   "metadata": {},
   "source": [
    "## Main loop\n",
    "Iterate all the cross validation folds to find the best one.\n",
    "\n",
    "For each of these, we do the full iteration of epochs with training and validation.\n",
    "Lastly, we run the test set on the given fold to see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5f42b3-d57c-4b85-9b7b-8d687f5b0020",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_train_loss, best_val_loss, best_model = blocked_training(\n",
    "    model=get_model(),\n",
    "    learning_rate=learning_rate,\n",
    "    device=device,\n",
    "    batch_size=batch_size,\n",
    "    lookback=lookback,\n",
    "    early_stopper=early_stopper,\n",
    ")\n",
    "\n",
    "\n",
    "x_test, y_test = get_test_set(lookback=lookback, horizon=horizon, folds=folds)\n",
    "test_dataset = TreforData(x_test, y_test, device)\n",
    "testing_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "t_loss, predicted = test_model(\n",
    "    best_model=best_model,\n",
    "    loss_function=loss_function,\n",
    "    testing_loader=testing_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f2eb43-a6d4-4ca7-a11d-8894dfaa204e",
   "metadata": {},
   "source": [
    "## Plotting\n",
    "Show some nice output :)\n",
    "### Training- and validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8de414-90df-4acd-84a1-bce9ce8b97e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.plot(best_train_loss, label=\"Training Loss\")\n",
    "plt.plot(best_val_loss, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ced0b9-627f-42bb-95be-ee368b27ae01",
   "metadata": {},
   "source": [
    "### Predictions- and actual consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7166c76-0af8-41ff-b48b-460f03f9e01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(110, 124, y_test, predicted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
