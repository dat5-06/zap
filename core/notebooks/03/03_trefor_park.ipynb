{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00beda90-5218-47db-a971-fe824c0b92cc",
   "metadata": {},
   "source": [
    "# 03 Trefor park"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2ed79f-f747-40a8-b370-f54496ff1e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from core.util.plot_predictions import plot_every_model\n",
    "from core.util.save_model import load_model, load_parameters\n",
    "from core.util.get_datasets import split_data, denormalize_data\n",
    "from core.util.trefor_dataset import TreforData\n",
    "from core.models import LSTM, GRU, CNNLSTM\n",
    "from core.models.model_training import test_model\n",
    "from core.util.hyperparameter_configuration import get_hyperparameter_configuration\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from core.util.metrics import mae, rmse, smape, adjusted_smape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0385b66-308f-41e6-b9b8-597225348dee",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "Parameters specific to this experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67712300-9f7e-4716-a493-654b4e805f7f",
   "metadata": {},
   "source": [
    "If the host has CUDA, it will use the GPU for computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffa0eff-01ad-4f3a-a126-2e2922e2c037",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0f727a-7861-4a27-97ea-e663f5bf3d08",
   "metadata": {},
   "source": [
    "## Change these\n",
    "Specify the features for this experiment, the best models and the experiment number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4685e80-cc1d-4e8d-b82d-c8c1454c83ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {\n",
    "    \"Month_x\": True,\n",
    "    \"Month_y\": True,\n",
    "    \"Hour_x\": True,\n",
    "    \"Hour_y\": True,\n",
    "    \"Day_x\": True,\n",
    "    \"Day_y\": True,\n",
    "}\n",
    "best_model_num = {\n",
    "    \"LSTM\": 2,\n",
    "    \"GRU\": 2,\n",
    "    \"CNN_LSTM\": 1,\n",
    "}\n",
    "experiment_no = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d53d5f-83e9-42be-935f-9f694df8cac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    k: load_parameters(f\"{experiment_no:02}_{k}_trefor_park_{v}\")\n",
    "    for k, v in best_model_num.items()\n",
    "}\n",
    "\n",
    "best_models = {\n",
    "    \"LSTM\": load_model(LSTM, f\"{experiment_no:02}_LSTM_trefor_park\", device),\n",
    "    \"GRU\": load_model(GRU, f\"{experiment_no:02}_GRU_trefor_park\", device),\n",
    "    \"CNN_LSTM\": load_model(CNNLSTM, f\"{experiment_no:02}_CNN_LSTM_trefor_park\", device),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2360699e-3f0e-4e94-877a-cd7020af815d",
   "metadata": {},
   "source": [
    "Global hyperparameter configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa453f99-03ae-4c85-8699-3a03afca2031",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = get_hyperparameter_configuration()\n",
    "loss_function = hyperparameters[\"loss_function\"]\n",
    "horizon = hyperparameters[\"horizon\"]\n",
    "train_days = hyperparameters[\"train_days\"]\n",
    "val_days = hyperparameters[\"val_days\"]\n",
    "test_days = hyperparameters[\"test_days\"]\n",
    "lookback = 96"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0617c025-6834-466c-aa64-f07bf95692ea",
   "metadata": {},
   "source": [
    "### Main loop\n",
    "Iterate all hyperparameter configuration to find the best one.\n",
    "\n",
    "For each of these, we do the full iteration of epochs (unless early stop occurs) with training and validation.\n",
    "Lastly, we run the test set on the given model to see how it performs using the metrics MAE, RMSE, and sMAPE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5f42b3-d57c-4b85-9b7b-8d687f5b0020",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, _, _, x_test, y_test = split_data(\n",
    "    lookback=lookback,\n",
    "    horizon=horizon,\n",
    "    train_days=train_days,\n",
    "    val_days=val_days,\n",
    "    test_days=test_days,\n",
    "    features=features,\n",
    ")\n",
    "\n",
    "results = {}\n",
    "\n",
    "# x-values for naive baseline regression\n",
    "# naive baseline is always 96 lookback window\n",
    "x = np.arange(96) - 96\n",
    "\n",
    "# iterate testset\n",
    "naive_prediction = []\n",
    "for item in x_test:\n",
    "    # check the entire lookback window, but only get the consumption\n",
    "    coef = np.polyfit(x, item[:, -1], 1)\n",
    "    regression_fn = np.poly1d(coef)\n",
    "    naive_prediction.append(regression_fn(np.arange(24)))\n",
    "naive_prediction = denormalize_data(naive_prediction)\n",
    "\n",
    "lagged_prediction = denormalize_data([item[-24:, -1] for item in x_test])\n",
    "\n",
    "# test each model\n",
    "for name, model in best_models.items():\n",
    "    lb = params[name][\"lookback\"]\n",
    "    lookback_specific_x = x_test[:, -lb:, :]\n",
    "    test_dataset = TreforData(lookback_specific_x, y_test, device)\n",
    "\n",
    "    testing_loader = DataLoader(\n",
    "        test_dataset, batch_size=params[name][\"batch_size\"], shuffle=False\n",
    "    )\n",
    "    _, predicted = test_model(\n",
    "        best_model=model,\n",
    "        loss_function=loss_function,\n",
    "        testing_loader=testing_loader,\n",
    "    )\n",
    "    results[name] = denormalize_data(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c677cb",
   "metadata": {},
   "source": [
    "In order to select the second best model we sort the results by lowest sMAPE.\n",
    "\n",
    "sMAPE is the chosen metric as the loss is lower when predictions are larger than the actual value compared to when predictions are lower than the actual value.\n",
    "$$\\hat{y} > y: \\text{lower loss} \\\\ \\hat{y} < y: \\text{greater loss}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f2eb43-a6d4-4ca7-a11d-8894dfaa204e",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ced0b9-627f-42bb-95be-ee368b27ae01",
   "metadata": {},
   "source": [
    "### Predictions- and actual consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7166c76-0af8-41ff-b48b-460f03f9e01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = denormalize_data(y_test)\n",
    "plot_every_model(\n",
    "    200,\n",
    "    202,\n",
    "    y_test,\n",
    "    naive_prediction,\n",
    "    lagged_prediction,\n",
    "    *results.values(),\n",
    "    f\"{experiment_no:02}.svg\",\n",
    ")\n",
    "\n",
    "plot_every_model(\n",
    "    200,\n",
    "    202,\n",
    "    y_test,\n",
    "    naive_prediction,\n",
    "    lagged_prediction,\n",
    "    *results.values(),\n",
    "    f\"{experiment_no:02}_12-offset.svg\",\n",
    "    12,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d89b9d1-f399-4c48-b85a-99d28e7150d3",
   "metadata": {},
   "source": [
    "## Loss for 48 hour period (one block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7134e9-da9a-4c98-84db-f3f7f0ccc707",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 200\n",
    "end = 202\n",
    "y_test_period = y_test[start * 24 : end * 24].flatten()\n",
    "\n",
    "\n",
    "models = {\n",
    "    \"LSTM\": results[\"LSTM\"][start * 24 : end * 24].flatten(),\n",
    "    \"GRU\": results[\"GRU\"][start * 24 : end * 24].flatten(),\n",
    "    \"CNN-LSTM\": results[\"CNN_LSTM\"][start * 24 : end * 24].flatten(),\n",
    "}\n",
    "\n",
    "loss = {}\n",
    "for name, block in models.items():\n",
    "    loss[name] = [\n",
    "        mae(y_test_period, block).item(),\n",
    "        rmse(y_test_period, block),\n",
    "        smape(y_test_period, block).item(),\n",
    "        adjusted_smape(y_test_period, block).item(),\n",
    "    ]\n",
    "\n",
    "pd.DataFrame(loss, index=[\"MAE\", \"RMSE\", \"sMAPE\", \"sMAPE w/o 0.05 lower bound\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
